{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2baeccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d2cef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Country  Age  Gender  Education Level   BMI Physical Activity Level  \\\n",
      "0         Spain   90    Male                1  33.0                  Medium   \n",
      "1     Argentina   72    Male                7  29.9                  Medium   \n",
      "2  South Africa   86  Female               19  22.9                    High   \n",
      "3         China   53    Male               17  31.2                     Low   \n",
      "4        Sweden   58  Female                3  30.0                    High   \n",
      "\n",
      "  Smoking Status Alcohol Consumption Diabetes Hypertension  ...  \\\n",
      "0          Never        Occasionally       No           No  ...   \n",
      "1         Former               Never       No           No  ...   \n",
      "2        Current        Occasionally       No          Yes  ...   \n",
      "3          Never           Regularly      Yes           No  ...   \n",
      "4         Former               Never      Yes           No  ...   \n",
      "\n",
      "  Dietary Habits Air Pollution Exposure  Employment Status Marital Status  \\\n",
      "0        Healthy                   High            Retired         Single   \n",
      "1        Healthy                 Medium         Unemployed        Widowed   \n",
      "2        Average                 Medium           Employed         Single   \n",
      "3        Healthy                 Medium            Retired         Single   \n",
      "4      Unhealthy                   High           Employed        Married   \n",
      "\n",
      "  Genetic Risk Factor (APOE-ε4 allele) Social Engagement Level Income Level  \\\n",
      "0                                   No                     Low       Medium   \n",
      "1                                   No                    High          Low   \n",
      "2                                   No                     Low       Medium   \n",
      "3                                   No                    High       Medium   \n",
      "4                                   No                     Low       Medium   \n",
      "\n",
      "  Stress Levels Urban vs Rural Living Alzheimer’s Diagnosis  \n",
      "0          High                 Urban                    No  \n",
      "1          High                 Urban                    No  \n",
      "2          High                 Rural                    No  \n",
      "3           Low                 Rural                    No  \n",
      "4          High                 Rural                    No  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataset_path = 'data/'  \n",
    "csv_file = os.path.join(dataset_path, 'alzheimers_prediction_dataset.csv')  \n",
    "df = pd.read_csv(csv_file)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db1b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_models_params = {\n",
    "    'lr': {\n",
    "        'model_cls': LogisticRegression,\n",
    "        'init_params': {'class_weight': 'balanced', 'random_state': 42, 'max_iter': 1000},\n",
    "        'param_grid': {'C': [0.01, 0.1, 1, 10]}\n",
    "    },\n",
    "    'rf': {\n",
    "        'model_cls': RandomForestClassifier,\n",
    "        'init_params': {'class_weight': 'balanced', 'random_state': 42},\n",
    "        'param_grid': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n",
    "    },\n",
    "    #'svm': {\n",
    "    #    'model_cls': SVC,\n",
    "    #    'init_params': {'probability': True, 'class_weight': 'balanced', 'random_state': 42},\n",
    "    #    'param_grid': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "    #},\n",
    "    'gb': {\n",
    "        'model_cls': GradientBoostingClassifier,\n",
    "        'init_params': {'random_state': 42},\n",
    "        'param_grid': {'n_estimators': [50, 100], 'max_depth': [3, 5]}\n",
    "    },\n",
    "    'knn': {\n",
    "        'model_cls': KNeighborsClassifier,\n",
    "        'init_params': {},\n",
    "        'param_grid': {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
    "    },\n",
    "    'xgb': {\n",
    "        'model_cls': XGBClassifier,\n",
    "        'init_params': {'random_state': 42, 'eval_metric': 'auc'},\n",
    "        'param_grid': {'n_estimators': [50, 100], 'max_depth': [3, 5], 'learning_rate': [0.01, 0.1]}\n",
    "    },\n",
    "    'mlp': {\n",
    "        'model_cls': MLPClassifier,\n",
    "        'init_params': {'random_state': 42, 'max_iter': 1000},\n",
    "        'param_grid': {'hidden_layer_sizes': [(50,), (100,)], 'activation': ['relu', 'tanh'], 'alpha': [0.0001, 0.001]}\n",
    "    }\n",
    "}\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "def train_and_save_models(df, models_params=None, validation=True, verbose=True):\n",
    "    \"\"\"Train models from scratch and save them. Handle multiple models, validation split, and performance logging.\"\"\"\n",
    "        \n",
    "    if models_params is None:\n",
    "        models_params = default_models_params\n",
    "    \n",
    "    X = df.drop('Alzheimer’s Diagnosis', axis=1)\n",
    "    y = df['Alzheimer’s Diagnosis'].map({'No': 0, 'Yes': 1})\n",
    "    \n",
    "    num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    cat_cols = X.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='mean')),\n",
    "                ('scaler', StandardScaler())\n",
    "            ]), num_cols),\n",
    "            ('cat', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "            ]), cat_cols)\n",
    "        ])\n",
    "    \n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    if validation:\n",
    "        # Split into train (60%), val (20%), test (20%)\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
    "        if verbose:\n",
    "            print(\"Data split: Train/Val/Test\")\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        X_val, y_val = None, None\n",
    "        if verbose:\n",
    "            print(\"Data split: Train/Test (no validation)\")\n",
    "    \n",
    "    trained_models = {}\n",
    "    \n",
    "    for model_name, model_info in models_params.items():\n",
    "        if verbose:\n",
    "            print(f\"\\nTraining {model_name}...\")\n",
    "        \n",
    "        model_cls = model_info['model_cls']\n",
    "        init_params = model_info.get('init_params', {}).copy()\n",
    "        \n",
    "        if model_name == 'xgb':\n",
    "            scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum() if (y_train == 1).sum() > 0 else 1\n",
    "            init_params['scale_pos_weight'] = scale_pos_weight\n",
    "            if verbose:\n",
    "                print(f\"Set scale_pos_weight to {scale_pos_weight} for XGBoost\")\n",
    "        \n",
    "        model = model_cls(**init_params)\n",
    "        grid = GridSearchCV(model, model_info['param_grid'], cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        \n",
    "        trained_models[model_name] = grid\n",
    "        \n",
    "        model_path = os.path.join('models', f'alzheimers_{model_name}_model.pkl')\n",
    "        joblib.dump(grid.best_estimator_, model_path)\n",
    "\n",
    "        #grid_path = os.path.join('models', f'alzheimers_{model_name}_gridsearch.pkl')\n",
    "        #joblib.dump(grid, grid_path)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Best params for {model_name}: {grid.best_params_}\")\n",
    "        \n",
    "        train_metrics = evaluate_model(X_train, y_train, model_type=model_name, processed_data=True, filepath=os.path.join('results', 'train_model_performances.csv'))\n",
    "        if verbose:\n",
    "            print(f\"{model_name} Train ROC-AUC: {train_metrics.get('roc_auc', 'N/A')}\")\n",
    "        \n",
    "        if validation and X_val is not None:\n",
    "            val_metrics = evaluate_model(X_val, y_val, model_type=model_name, processed_data=True, filepath=os.path.join('results', 'val_model_performances.csv'))\n",
    "            if verbose:\n",
    "                print(f\"{model_name} Val ROC-AUC: {val_metrics.get('roc_auc', 'N/A')}\")\n",
    "    \n",
    "    preprocessor_path = os.path.join('models', 'preprocessor.pkl')\n",
    "    joblib.dump(preprocessor, preprocessor_path)\n",
    "\n",
    "    feature_info_path = os.path.join('models', 'feature_info.pkl')\n",
    "    joblib.dump({\n",
    "        'num_cols': list(num_cols),\n",
    "        'cat_cols': list(cat_cols),\n",
    "        'all_features': list(X.columns)\n",
    "    }, feature_info_path)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nModels, preprocessor, and feature info saved successfully!\")\n",
    "        print(f\"Models saved in: {os.path.relpath('models')}\")\n",
    "        print(f\"Results saved in: {os.path.relpath('results')}\")\n",
    "    \n",
    "    return trained_models, preprocessor, X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def load_models_and_preprocessor(model_types=None):\n",
    "    \"\"\"Load previously saved models and preprocessor.\"\"\"\n",
    "    if model_types is None:\n",
    "        model_types = list(default_models_params.keys()) \n",
    "    \n",
    "    if isinstance(model_types, str):\n",
    "        model_types = [model_types]\n",
    "    \n",
    "    models = {}\n",
    "    for mt in model_types:\n",
    "        try:\n",
    "            model_path = os.path.join('models', f'alzheimers_{mt}_model.pkl')\n",
    "            models[mt] = joblib.load(model_path)\n",
    "            print(f\"Loaded {mt} model from: {os.path.relpath(model_path)}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {mt} model file not found in models folder.\")\n",
    "            alt_path = f'alzheimers_{mt}_model.pkl'\n",
    "            if os.path.exists(alt_path):\n",
    "                models[mt] = joblib.load(alt_path)\n",
    "                print(f\"Loaded {mt} model from alternative location: {alt_path}\")\n",
    "    \n",
    "    try:\n",
    "        preprocessor_path = os.path.join('models', 'preprocessor.pkl')\n",
    "        preprocessor = joblib.load(preprocessor_path)\n",
    "        \n",
    "        feature_info_path = os.path.join('models', 'feature_info.pkl')\n",
    "        feature_info = joblib.load(feature_info_path)\n",
    "        \n",
    "        print(f\"Loaded preprocessor and feature info from models folder\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading preprocessor or feature info: {e}\")\n",
    "        try:\n",
    "            preprocessor = joblib.load('preprocessor.pkl')\n",
    "            feature_info = joblib.load('feature_info.pkl')\n",
    "            print(\"Loaded from alternative locations\")\n",
    "        except:\n",
    "            preprocessor = None\n",
    "            feature_info = None\n",
    "    \n",
    "    return models, preprocessor, feature_info\n",
    "\n",
    "def evaluate_model(new_X, new_y, model_type='rf', processed_data=False, filepath=None):\n",
    "    \"\"\"\n",
    "    Evaluate model performance on new data.\n",
    "    \"\"\"\n",
    "    if filepath is None:\n",
    "        filepath = os.path.join('results', 'model_performances.csv')\n",
    "    elif not os.path.dirname(filepath):  \n",
    "        filepath = os.path.join('results', filepath)\n",
    "\n",
    "    if isinstance(model_type, list):\n",
    "        models, preprocessor, _ = load_models_and_preprocessor(model_type)\n",
    "        metrics_dict = {}\n",
    "        for mt in model_type:\n",
    "            if mt not in models:\n",
    "                continue\n",
    "            model = models[mt]\n",
    "            metrics_dict[mt] = _compute_metrics(new_X, new_y, model, preprocessor, processed_data)\n",
    "        \n",
    "        if metrics_dict:\n",
    "            metrics_df = pd.DataFrame.from_dict(metrics_dict, orient='index')\n",
    "            metrics_df.to_csv(filepath, index_label='model')\n",
    "            print(f\"Performances saved to {filepath}\")\n",
    "            \n",
    "            best_model = metrics_df['roc_auc'].idxmax()\n",
    "            best_score = metrics_df['roc_auc'].max()\n",
    "            print(f\"Best model: {best_model} with ROC-AUC {best_score}\")\n",
    "            return metrics_dict, best_model\n",
    "        else:\n",
    "            return {}, None\n",
    "    \n",
    "    else:\n",
    "        models, preprocessor, _ = load_models_and_preprocessor([model_type])\n",
    "        model = models.get(model_type)\n",
    "        if model is None:\n",
    "            print(f\"Error: Model {model_type} not loaded.\")\n",
    "            return {}\n",
    "\n",
    "        metrics = _compute_metrics(new_X, new_y, model, preprocessor, processed_data)\n",
    "\n",
    "        if filepath:\n",
    "            timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
    "            individual_path = os.path.join('results', f'{model_type}_performance_{timestamp}.csv')\n",
    "            pd.DataFrame([metrics]).to_csv(individual_path, index=False)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "def _compute_metrics(new_X, new_y, model, preprocessor, processed_data):\n",
    "    \"\"\"Helper to compute metrics\"\"\"\n",
    "\n",
    "    if not processed_data:\n",
    "        new_X = preprocessor.transform(new_X)\n",
    "    \n",
    "    y_pred = model.predict(new_X)\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(new_y, y_pred),\n",
    "        'precision': precision_score(new_y, y_pred, zero_division=0),\n",
    "        'recall': recall_score(new_y, y_pred, zero_division=0),\n",
    "        'f1_score': f1_score(new_y, y_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(new_X)[:, 1]\n",
    "        metrics['roc_auc'] = roc_auc_score(new_y, y_pred_proba)\n",
    "\n",
    "    cm = confusion_matrix(new_y, y_pred)\n",
    "    metrics['tn'], metrics['fp'], metrics['fn'], metrics['tp'] = cm.ravel()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdabb043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: Train/Val/Test\n",
      "\n",
      "Training lr...\n",
      "Best params for lr: {'C': 0.1}\n",
      "Loaded lr model from: models/alzheimers_lr_model.pkl\n",
      "Error loading preprocessor or feature info: [Errno 2] No such file or directory: 'models/preprocessor.pkl'\n",
      "lr Train ROC-AUC: 0.7917843261176399\n",
      "Loaded lr model from: models/alzheimers_lr_model.pkl\n",
      "Error loading preprocessor or feature info: [Errno 2] No such file or directory: 'models/preprocessor.pkl'\n",
      "lr Val ROC-AUC: 0.7859223021842926\n",
      "\n",
      "Training rf...\n",
      "Best params for rf: {'max_depth': 10, 'n_estimators': 200}\n",
      "Loaded rf model from: models/alzheimers_rf_model.pkl\n",
      "Error loading preprocessor or feature info: [Errno 2] No such file or directory: 'models/preprocessor.pkl'\n",
      "rf Train ROC-AUC: 0.8519246963570855\n",
      "Loaded rf model from: models/alzheimers_rf_model.pkl\n",
      "Error loading preprocessor or feature info: [Errno 2] No such file or directory: 'models/preprocessor.pkl'\n",
      "rf Val ROC-AUC: 0.7950601140270571\n",
      "\n",
      "Training gb...\n",
      "Best params for gb: {'max_depth': 3, 'n_estimators': 100}\n",
      "Loaded gb model from: models/alzheimers_gb_model.pkl\n",
      "Error loading preprocessor or feature info: [Errno 2] No such file or directory: 'models/preprocessor.pkl'\n",
      "gb Train ROC-AUC: 0.8088719036349339\n",
      "Loaded gb model from: models/alzheimers_gb_model.pkl\n",
      "Error loading preprocessor or feature info: [Errno 2] No such file or directory: 'models/preprocessor.pkl'\n",
      "gb Val ROC-AUC: 0.7995923489927219\n",
      "\n",
      "Training knn...\n",
      "Best params for knn: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "Loaded knn model from: models/alzheimers_knn_model.pkl\n",
      "Error loading preprocessor or feature info: [Errno 2] No such file or directory: 'models/preprocessor.pkl'\n",
      "knn Train ROC-AUC: 1.0\n",
      "Loaded knn model from: models/alzheimers_knn_model.pkl\n",
      "Error loading preprocessor or feature info: [Errno 2] No such file or directory: 'models/preprocessor.pkl'\n",
      "knn Val ROC-AUC: 0.7017675027034322\n",
      "\n",
      "Training xgb...\n",
      "Set scale_pos_weight to 1.4186791121723559 for XGBoost\n",
      "Best params for xgb: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Loaded xgb model from: models/alzheimers_xgb_model.pkl\n",
      "Error loading preprocessor or feature info: [Errno 2] No such file or directory: 'models/preprocessor.pkl'\n",
      "xgb Train ROC-AUC: 0.8054427037173737\n",
      "Loaded xgb model from: models/alzheimers_xgb_model.pkl\n",
      "Error loading preprocessor or feature info: [Errno 2] No such file or directory: 'models/preprocessor.pkl'\n",
      "xgb Val ROC-AUC: 0.7998518104822591\n",
      "\n",
      "Training mlp...\n",
      "Best params for mlp: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50,)}\n",
      "Loaded mlp model from: models/alzheimers_mlp_model.pkl\n",
      "Error loading preprocessor or feature info: [Errno 2] No such file or directory: 'models/preprocessor.pkl'\n",
      "mlp Train ROC-AUC: 0.8386792486005431\n",
      "Loaded mlp model from: models/alzheimers_mlp_model.pkl\n",
      "Error loading preprocessor or feature info: [Errno 2] No such file or directory: 'models/preprocessor.pkl'\n",
      "mlp Val ROC-AUC: 0.7603415551122993\n",
      "\n",
      "Models, preprocessor, and feature info saved successfully!\n",
      "Models saved in: models\n",
      "Results saved in: results\n"
     ]
    }
   ],
   "source": [
    "trained_models, preprocessor, X_train, X_val, X_test, y_train, y_val, y_test = train_and_save_models(df, models_params=default_models_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7e688c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded lr model from: models/alzheimers_lr_model.pkl\n",
      "Loaded rf model from: models/alzheimers_rf_model.pkl\n",
      "Loaded gb model from: models/alzheimers_gb_model.pkl\n",
      "Loaded knn model from: models/alzheimers_knn_model.pkl\n",
      "Loaded xgb model from: models/alzheimers_xgb_model.pkl\n",
      "Loaded mlp model from: models/alzheimers_mlp_model.pkl\n",
      "Loaded preprocessor and feature info from models folder\n",
      "Performances saved to results/test_model_performances.csv\n",
      "Best model: xgb with ROC-AUC 0.808035747811577\n"
     ]
    }
   ],
   "source": [
    "metrics, best = evaluate_model(X_test, y_test, model_type=['lr', 'rf', 'gb', 'knn', 'xgb', 'mlp'], processed_data=True, filepath='test_model_performances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_alzheimers(new_data_dict, model_type='rf', \n",
    "                       model=None, preprocessor=None, \n",
    "                       feature_info=None, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict Alzheimer's diagnosis for new sample\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    new_data_dict : dict\n",
    "        Dictionary containing feature values\n",
    "    model_type : str\n",
    "        Model type key, e.g., 'rf', 'xgb', etc.\n",
    "    model : trained model or dict of models\n",
    "        If None, loads from saved file\n",
    "    preprocessor : fitted preprocessor\n",
    "        If None, loads from saved file\n",
    "    feature_info : dict\n",
    "        Feature metadata, loaded if None\n",
    "    threshold : float\n",
    "        Decision threshold\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: Prediction results\n",
    "    \"\"\"\n",
    "    \n",
    "    if model is None or preprocessor is None or feature_info is None:\n",
    "        models, preprocessor, feature_info = load_models_and_preprocessor(model_types=model_type)\n",
    "        if not models or model_type not in models:\n",
    "            return {\"error\": f\"Model {model_type} not loaded\"}\n",
    "        model = models[model_type]\n",
    "    elif isinstance(model, dict):\n",
    "        if model_type in model:\n",
    "            model = model[model_type]\n",
    "        else:\n",
    "            return {\"error\": f\"Model {model_type} not found in provided dict\"}\n",
    "    \n",
    "    new_df = pd.DataFrame([new_data_dict])\n",
    "    \n",
    "    expected_features = feature_info['all_features']\n",
    "    missing_features = set(expected_features) - set(new_df.columns)\n",
    "    extra_features = set(new_df.columns) - set(expected_features)\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"Warning: Missing features: {missing_features}\")\n",
    "        for feat in missing_features:\n",
    "            new_df[feat] = np.nan\n",
    "    \n",
    "    if extra_features:\n",
    "        print(f\"Warning: Extra features provided: {extra_features}\")\n",
    "        new_df = new_df[expected_features]\n",
    "    \n",
    "    try:\n",
    "        new_processed = preprocessor.transform(new_df)\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Preprocessing failed: {str(e)}\"}\n",
    "    \n",
    "    try:\n",
    "        prob = model.predict_proba(new_processed)[0][1]\n",
    "        prediction = 1 if prob >= threshold else 0\n",
    "        confidence = prob if prediction == 1 else 1 - prob\n",
    "        \n",
    "        feature_importance = None\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importance_dict = dict(zip(\n",
    "                preprocessor.get_feature_names_out(),\n",
    "                model.feature_importances_\n",
    "            ))\n",
    "\n",
    "            top_features = sorted(importance_dict.items(), \n",
    "                                 key=lambda x: x[1], \n",
    "                                 reverse=True)[:10]\n",
    "            feature_importance = dict(top_features)\n",
    "        \n",
    "        result = {\n",
    "            'diagnosis': 'Yes' if prediction == 1 else 'No',\n",
    "            'probability': float(prob),\n",
    "            'confidence': float(confidence),\n",
    "            'threshold_used': float(threshold),\n",
    "            'model_used': model_type.upper(),\n",
    "            'feature_importance': feature_importance,\n",
    "            'risk_level': categorize_risk(prob)\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Prediction failed: {str(e)}\"}\n",
    "\n",
    "def categorize_risk(probability):\n",
    "    \"\"\"Categorize risk based on probability\"\"\"\n",
    "    if probability < 0.3:\n",
    "        return \"Low Risk\"\n",
    "    elif probability < 0.6:\n",
    "        return \"Moderate Risk\"\n",
    "    elif probability < 0.8:\n",
    "        return \"High Risk\"\n",
    "    else:\n",
    "        return \"Very High Risk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddf557e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(new_data_df, model_type='rf', threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict for multiple samples at once\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    new_data_df : pandas DataFrame\n",
    "        DataFrame containing multiple samples\n",
    "    model_type : str\n",
    "        Model type key, e.g., 'rf', 'xgb', etc.\n",
    "    threshold : float\n",
    "        Decision threshold\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    models, preprocessor, feature_info = load_models_and_preprocessor(model_types=model_type)\n",
    "    if not models or model_type not in models:\n",
    "        print(f\"Error: Model {model_type} not loaded.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    model = models[model_type]\n",
    "    \n",
    "    expected_features = feature_info['all_features']\n",
    "    missing_features = set(expected_features) - set(new_data_df.columns)\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"Warning: Adding missing features: {missing_features}\")\n",
    "        for feat in missing_features:\n",
    "            new_data_df[feat] = np.nan\n",
    "    \n",
    "    new_data_df = new_data_df[expected_features]\n",
    "    \n",
    "    try:\n",
    "        new_processed = preprocessor.transform(new_data_df)\n",
    "        probabilities = model.predict_proba(new_processed)[:, 1]\n",
    "        predictions = (probabilities >= threshold).astype(int)\n",
    "        \n",
    "        results_df = new_data_df.copy()\n",
    "        results_df['Predicted_Diagnosis'] = ['Yes' if p == 1 else 'No' for p in predictions]\n",
    "        results_df['Probability'] = probabilities\n",
    "        results_df['Risk_Level'] = [categorize_risk(p) for p in probabilities]\n",
    "        results_df['Confidence'] = np.where(\n",
    "            predictions == 1, \n",
    "            probabilities, \n",
    "            1 - probabilities\n",
    "        )\n",
    "        \n",
    "        return results_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Batch prediction failed: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "190dadbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rf model from: models/alzheimers_rf_model.pkl\n",
      "Loaded preprocessor and feature info from models folder\n",
      "Prediction Result: {'diagnosis': 'No', 'probability': 0.5783215743096121, 'confidence': 0.42167842569038794, 'threshold_used': 0.6, 'model_used': 'RF', 'feature_importance': {'num__Age': np.float64(0.532863160495897), 'cat__Genetic Risk Factor (APOE-ε4 allele)_Yes': np.float64(0.07499109500973443), 'cat__Genetic Risk Factor (APOE-ε4 allele)_No': np.float64(0.06706637613135394), 'cat__Family History of Alzheimer’s_Yes': np.float64(0.036600016802217306), 'cat__Family History of Alzheimer’s_No': np.float64(0.034773984724978585), 'num__BMI': np.float64(0.024464707897405007), 'num__Cognitive Test Score': np.float64(0.021825002180314853), 'num__Education Level': np.float64(0.017660896145939874), 'cat__Country_Russia': np.float64(0.005330747689847775), 'cat__Country_India': np.float64(0.004808221185982292)}, 'risk_level': 'Moderate Risk'}\n"
     ]
    }
   ],
   "source": [
    "sample_patient = {\n",
    "    'Country': 'Spain',\n",
    "    'Age': 90,\n",
    "    'Gender': 'Male',\n",
    "    'Education Level': 1,\n",
    "    'BMI': 33.0,\n",
    "    'Physical Activity Level': 'Medium',\n",
    "    'Smoking Status': 'Never',\n",
    "    'Alcohol Consumption': 'Occasionally',\n",
    "    'Diabetes': 'No',\n",
    "    'Hypertension': 'No',\n",
    "    'Cholesterol Level': 'Normal',\n",
    "    'Family History of Alzheimer’s': 'No',\n",
    "    'Cognitive Test Score': 90,\n",
    "    'Depression Level': 'Low',\n",
    "    'Sleep Quality': 'Poor',\n",
    "    'Dietary Habits': 'Healthy',\n",
    "    'Air Pollution Exposure': 'High',\n",
    "    'Employment Status': 'Retured',\n",
    "    'Marital Status': 'Single',\n",
    "    'Genetic Risk Factor (APOE-ε4 allele)': 'No',\n",
    "    'Social Engagement Level': 'Low',\n",
    "    'Income Level': 'Medium',\n",
    "    'Stress Levels': 'High',\n",
    "    'Urban vs Rural Living': 'Urban'\n",
    "}\n",
    "\n",
    "# Alzheimer’s Diagnosis ==> No\n",
    "sample_patient2 = {\n",
    "        'Country': 'USA',\n",
    "        'Age': 30,\n",
    "        'Gender': 'Male',\n",
    "        'Education Level': 12,\n",
    "        'BMI': 26.5,\n",
    "        'Physical Activity Level': 'Medium',\n",
    "        'Smoking Status': 'Former',\n",
    "        'Alcohol Consumption': 'Moderate',\n",
    "        'Diabetes': 'No',\n",
    "        'Hypertension': 'Yes',\n",
    "        'Cholesterol Level': 'High',\n",
    "        'Family History of Alzheimer’s': 'Yes',\n",
    "        'Genetic Risk Factor (APOE-ε4 allele)': 'Yes',\n",
    "        'Cognitive Test Score': 22,\n",
    "        'Depression Level': 'Low',\n",
    "        'Sleep Quality': 'Poor',\n",
    "        'Dietary Habits': 'Average',\n",
    "        'Employment Status': 'Retired',\n",
    "        'Marital Status': 'Married',\n",
    "        'Social Engagement Level': 'Medium',\n",
    "        'Income Level': 'Middle',\n",
    "        'Stress Levels': 'Medium',\n",
    "        'Urban vs Rural Living': 'Urban',\n",
    "        'Air Pollution Exposure': 'Medium'\n",
    "    }\n",
    "    \n",
    "model, preprocessor, feature_info = load_models_and_preprocessor(model_types='rf')\n",
    "\n",
    "result = predict_alzheimers(\n",
    "        sample_patient,\n",
    "        model_type='rf',\n",
    "        model=model, \n",
    "        preprocessor=preprocessor, \n",
    "        feature_info=feature_info,\n",
    "        threshold=0.6\n",
    "    )\n",
    "    \n",
    "print(f\"Prediction Result: {result}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191cbd58",
   "metadata": {},
   "source": [
    "## Would the model performance improve if top 10 feature importance were used to train the models?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
